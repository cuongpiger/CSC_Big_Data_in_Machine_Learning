{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit207240a302f84cf383d7b6dbf8fca3f2",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql.functions import mean, stddev, col, log\n",
    "from pyspark.sql.functions import to_date, dayofweek, to_timestamp\n",
    "from pyspark.sql import types \n",
    "from pyspark.sql.functions import col, udf\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql.functions import year, month\n",
    "from pyspark.sql.functions import dayofmonth, weekofyear\n",
    "from pyspark.sql.functions import split, explode\n",
    "from pyspark.sql.functions import coalesce, first, lit\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml.feature import Bucketizer\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "from pyspark.sql.functions import regexp_extract, col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.pyspark import CPySpark\n",
    "from pyspark.sql import Row, SQLContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = CPySpark(session=True, sql=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = spark.session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+----------+-----------------+---------------+-----+-----------------+---------------+---------+------------+\n|STREETNUMBERNUMERIC|FIREPLACES|LOTSIZEDIMENSIONS|       LISTTYPE|ACRES|ASSUMABLEMORTGAGE|SalesClosePrice|ListPrice|DAYSONMARKET|\n+-------------------+----------+-----------------+---------------+-----+-----------------+---------------+---------+------------+\n|              11511|         0|          279X200|Exclusive Right| 1.28|             null|         143000|   139900|          10|\n|              11200|         0|          100x140|Exclusive Right| 0.32|             null|         190000|   210000|           4|\n|               8583|         0|          120x296|Exclusive Right|0.822|    Not Assumable|         225000|   225000|          28|\n|               9350|         1|          208X208|Exclusive Right| 0.94|             null|         265000|   230000|          19|\n|               2915|         1|          116x200|Exclusive Right|  0.0|             null|         249900|   239900|          21|\n+-------------------+----------+-----------------+---------------+-----+-----------------+---------------+---------+------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"./data/2017_StPaul_MN_Real_Estate.csv\", header=True, inferSchema=True)\n",
    "\n",
    "df_sub = df.select('STREETNUMBERNUMERIC', 'FIREPLACES', \n",
    "                   'LOTSIZEDIMENSIONS', 'LISTTYPE', 'ACRES', \n",
    "                   'ASSUMABLEMORTGAGE', 'SalesClosePrice', 'ListPrice',\n",
    "                   'DAYSONMARKET')\n",
    "df_sub.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}