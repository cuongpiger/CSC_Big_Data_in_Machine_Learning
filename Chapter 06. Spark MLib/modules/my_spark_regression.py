import pyspark

from pyspark.ml.feature import VectorAssembler
from pyspark.ml.regression import LinearRegression
from typing import List


from modules.my_drawer import MyDrawer


class MySparkRegression:
    def __init__(self, pData: pyspark.RDD, pPredictorFeatures: List[str], pTargetFeature: str):
        self.data: pyspark.RDD = pData  # raw data
        # features from `pData` used to training model
        self.predictor_features: List[str] = pPredictorFeatures
        self.target_feature: str = pTargetFeature
        self.df_data: pyspark.sql.DataFrame = None
        self.train_data: pyspark.sql.DataFrame = None
        self.test_data: pyspark.sql.DataFrame = None

    def prepareData(self):
        """ Ph∆∞∆°ng th·ª©c n√†y d√πng ƒë·ªÉ chu·∫©n b·ªã d·ªØ li·ªáu cho model, c·ª• th·ªÉ n√≥ s·∫Ω chuy·ªÉn t·∫•t c·∫£ c√°c thu·ªôc t√≠nh
                trong `self.predictor_features` th√†nh m·ªôt vector v·ªõi s·ªë chi·ªÅu la length c·ªßa 
                `self.predictor_features`, cu·ªëi c√πng ƒë·∫∑t t√™n cho vector n√†y l√† `features`
        """
        vector_assembler = VectorAssembler(
            inputCols=self.predictor_features, outputCol='features')
        self.df_data = vector_assembler.transform(
            self.data).select('features', self.target_feature)

    def trainTestSplit(self, pTrainSize: float = .75):
        """ T√°ch d·ªØ li·ªáu ban ƒë·∫ßu th√†nh train data v√† test data v·ªõi size c·ªßa train data dc quy ƒë·ªãnh b·ªüi
                tham s·ªë `pTrainSize`
        Args:
            pTrainSize (float, optional): K√≠ch th∆∞·ªõc c·ªßa `self.train_data`
        """
        if self.df_data is None:
            print("üö´ Please call method prepareData() before calling this method!")
            return

        self.train_data, self.test_data = self.df_data.randomSplit(
            (pTrainSize, 1 - pTrainSize))


    def describeTarget(self, visual=False):
        train_target_col = self.target_feature + " (train)"
        test_target_col = self.target_feature + " (test)"
        
        train_describe: pyspark.sql.DataFrame = self.train_data.select(self.target_feature).describe().withColumnRenamed(self.target_feature, train_target_col)
        test_describe: pyspark.sql.DataFrame = self.test_data.select(self.target_feature).describe().withColumnRenamed(self.target_feature, test_target_col)
        entire_describe: pyspark.sql.DataFrame = train_describe.join(test_describe, on="summary")
        
        if visual:
            describeTargetVisual()
        
        return train_describe.join(test_describe, on="summary")
    
    
    
def describeTargetVisual(pDesribeDataFrame: pyspark.sql.DataFrame):
    y_scale = pDesribeDataFrame.select('summary')