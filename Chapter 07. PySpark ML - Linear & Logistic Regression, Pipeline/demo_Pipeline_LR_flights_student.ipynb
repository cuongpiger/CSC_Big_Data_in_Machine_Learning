{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "name": "python38564bit207240a302f84cf383d7b6dbf8fca3f2",
      "display_name": "Python 3.8.5 64-bit"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "demo_Pipeline_LR_flights_student.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "metadata": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htieX36WILOL"
      },
      "source": [
        "# Demo Pipeline Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX15GVB5ILOL"
      },
      "source": [
        "### Dataset: flights.csv\n",
        "- You'll build a regression model to predict flight duration \n",
        "- With dow, org, mile as a predictor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07jAfrdhILOM"
      },
      "source": [
        "First thing to do is start a Spark Session"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56yI2SNpILOO"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HTl7r5lTILOQ"
      },
      "source": [
        "import pyspark"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEAWgYNVILOT"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.conf import SparkConf\n",
        "from pyspark.sql import SparkSession"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z3YBe6bILOV"
      },
      "source": [
        "spark = SparkSession.builder.appName('lr_demo').getOrCreate()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9--eXhWQILOX"
      },
      "source": [
        "# Use Spark to read in the Ecommerce Customers csv file.\n",
        "data = spark.read.csv(\"./data/flights.csv\",inferSchema=True,header=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Gc7RpCILOZ",
        "outputId": "b1b5df58-d984-4818-c203-c8ea8f9e1cd8"
      },
      "source": [
        "# Print the Schema of the DataFrame\n",
        "data.printSchema()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n |-- mon: integer (nullable = true)\n |-- dom: integer (nullable = true)\n |-- dow: integer (nullable = true)\n |-- carrier: string (nullable = true)\n |-- flight: integer (nullable = true)\n |-- org: string (nullable = true)\n |-- mile: integer (nullable = true)\n |-- depart: double (nullable = true)\n |-- duration: integer (nullable = true)\n |-- delay: string (nullable = true)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKMl-nIvILOe",
        "outputId": "de5c3a95-43e9-4367-f42a-278c2daeaa3f"
      },
      "source": [
        "data.show(3)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+-------+------+---+----+------+--------+-----+\n|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n+---+---+---+-------+------+---+----+------+--------+-----+\n| 11| 20|  6|     US|    19|JFK|2153|  9.48|     351|   NA|\n|  0| 22|  2|     UA|  1107|ORD| 316| 16.33|      82|   30|\n|  2| 20|  4|     UA|   226|SFO| 337|  6.17|      82|   -8|\n+---+---+---+-------+------+---+----+------+--------+-----+\nonly showing top 3 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlEOiqwtILOh",
        "outputId": "92fc43c8-5fe9-4c3c-9aad-2aa3f4cebcef"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(mon=11, dom=20, dow=6, carrier='US', flight=19, org='JFK', mile=2153, depart=9.48, duration=351, delay='NA')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWfwRZEMILOj"
      },
      "source": [
        "# for item in data.head():\n",
        "#     print(item)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkonA9VXILOl",
        "outputId": "99876fa5-6e5a-4ada-f008-b55f378ae5ee"
      },
      "source": [
        "data.count()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS8SkhJWILOo"
      },
      "source": [
        "# Remove the 'flight' column\n",
        "data = data.drop('flight')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVArl35CILOq",
        "outputId": "3be1251e-eade-4c01-f786-bc982d7009cd"
      },
      "source": [
        "# Number of records with missing 'delay' values\n",
        "data.filter('delay IS NULL').count()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9c00fcpILOs"
      },
      "source": [
        "# Remove records with missing 'delay' values\n",
        "data = data.filter('delay IS NOT NULL')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4-ITkOsILOv",
        "outputId": "a0e180a2-45cf-4afb-b6ce-d9333ccaeaea"
      },
      "source": [
        "# Remove records with missing values in any column and get the number of remaining rows\n",
        "data = data.na.drop()\n",
        "data.count()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5vet7cwILOx"
      },
      "source": [
        "# Import the required function\n",
        "from pyspark.sql.functions import round"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLj744ytILOz"
      },
      "source": [
        "# Convert 'mile' to 'km' and drop 'mile' column\n",
        "data = data.withColumn('km', round(data.mile * 1.60934, 0))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVH4QEMdILO1",
        "outputId": "24f17c56-8a4a-4912-fb03-a06b82b4259e"
      },
      "source": [
        "# Create 'label' column indicating whether flight delayed (1) or not (0)\n",
        "data = data.withColumn('label', (data.delay >= 15).cast('integer'))\n",
        "# Check first five records\n",
        "data.show(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+-------+---+----+------+--------+-----+------+-----+\n|mon|dom|dow|carrier|org|mile|depart|duration|delay|    km|label|\n+---+---+---+-------+---+----+------+--------+-----+------+-----+\n| 11| 20|  6|     US|JFK|2153|  9.48|     351|   NA|3465.0| null|\n|  0| 22|  2|     UA|ORD| 316| 16.33|      82|   30| 509.0|    1|\n|  2| 20|  4|     UA|SFO| 337|  6.17|      82|   -8| 542.0|    0|\n|  9| 13|  1|     AA|ORD|1236| 10.33|     195|   -5|1989.0|    0|\n|  4|  2|  5|     AA|ORD| 258|  8.92|      65|   NA| 415.0| null|\n+---+---+---+-------+---+----+------+--------+-----+------+-----+\nonly showing top 5 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x81Ip4tDILO_",
        "outputId": "5d51f7db-93a6-48e3-93af-33978c072c87"
      },
      "source": [
        "final_data = data\n",
        "final_data.count()\n",
        "\n",
        "final_data = final_data.na.drop()\n",
        "final_data.count()\n",
        "\n",
        "final_data.show(5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+---+-------+---+----+------+--------+-----+------+-----+\n|mon|dom|dow|carrier|org|mile|depart|duration|delay|    km|label|\n+---+---+---+-------+---+----+------+--------+-----+------+-----+\n|  0| 22|  2|     UA|ORD| 316| 16.33|      82|   30| 509.0|    1|\n|  2| 20|  4|     UA|SFO| 337|  6.17|      82|   -8| 542.0|    0|\n|  9| 13|  1|     AA|ORD|1236| 10.33|     195|   -5|1989.0|    0|\n|  5|  2|  1|     UA|SFO| 550|  7.98|     102|    2| 885.0|    0|\n|  7|  2|  6|     AA|ORD| 733| 10.83|     135|   54|1180.0|    1|\n+---+---+---+-------+---+----+------+--------+-----+------+-----+\nonly showing top 5 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFJSoLs_wZuO"
      },
      "source": [
        "# Thực hiện Pipeline\n",
        "- ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data, test_data = final_data.randomSplit([0.8, 0.2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.sql.functions import corr\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "indexer = StringIndexer(inputCol='org', outputCol='org_idx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "onehot = OneHotEncoder(inputCols=['org_idx', 'dow'], outputCols=['org_dummy', 'dow_dummy'])\n",
        "assembler = VectorAssembler(inputCols=['km', 'org_dummy', 'dow_dummy'], outputCol='features')\n",
        "\n",
        "regression = LinearRegression(featuresCol='features', labelCol='duration', predictionCol='prediction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[indexer, onehot, assembler, regression])\n",
        "pipeline = pipeline.fit(train_data)"
      ]
    },
    {
      "source": [
        "* Đánh giá kết quả"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = pipeline.transform(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+--------+\n|        prediction|duration|\n+------------------+--------+\n| 312.0877373567421|     310|\n| 92.24408654787044|      90|\n|131.68943970413105|     130|\n| 250.3969243438758|     260|\n| 291.7736883891435|     270|\n+------------------+--------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "predictions.select('prediction', 'duration').show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.94740490075749"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "RegressionEvaluator(labelCol='duration').evaluate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline.save('./data/pipeline_flights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyspark.ml import PipelineModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipelines = PipelineModel.load('./data/pipeline_flights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "unlabeled_data = test_data.drop('label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions2 = pipelines.transform(unlabeled_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n|            features|        prediction|\n+--------------------+------------------+\n|(14,[0,10],[4001....| 312.0877373567421|\n|(14,[0,1,10],[649...| 92.24408654787044|\n|(14,[0,1,10],[118...|131.68943970413105|\n|(14,[0,1,10],[277...| 250.3969243438758|\n|(14,[0,1,10],[333...| 291.7736883891435|\n+--------------------+------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "predictions2.select('features', 'prediction').show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}