{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit207240a302f84cf383d7b6dbf8fca3f2",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "![](images/11_01.jpg)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. Đọc dữ liệu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('nlp_musical').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.json(\"./data/Musical_Instruments_5.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n|      asin| helpful|overall|          reviewText| reviewTime|    reviewerID|        reviewerName|             summary|unixReviewTime|\n+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\n|1384719342|  [0, 0]|    5.0|Not much to write...|02 28, 2014|A2IBPI20UZIR0U|cassandra tu \"Yea...|                good|    1393545600|\n|1384719342|[13, 14]|    5.0|The product does ...|03 16, 2013|A14VAT5EAX3D9S|                Jake|                Jake|    1363392000|\n|1384719342|  [1, 1]|    5.0|The primary job o...|08 28, 2013|A195EZSQDW3E21|Rick Bennette \"Ri...|It Does The Job Well|    1377648000|\n|1384719342|  [0, 0]|    5.0|Nice windscreen p...|02 14, 2014|A2C00NNG1ZQQG2|RustyBill \"Sunday...|GOOD WINDSCREEN F...|    1392336000|\n|1384719342|  [0, 0]|    5.0|This pop filter i...|02 21, 2014| A94QU4C90B1AX|       SEAN MASLANKA|No more pops when...|    1392940800|\n+----------+--------+-------+--------------------+-----------+--------------+--------------------+--------------------+--------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('class', when(data['overall'] >= 4, 'like')\n",
    "                                .when(data['overall'] <= 2, 'not_like')\n",
    "                                .otherwise(\"neutral\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select('reviewText', 'overall', 'class')"
   ]
  },
  {
   "source": [
    "# 2. Làm sạch và chuẩn dữ liệu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('length', length(data['reviewText']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+-------+-----+------+\n|          reviewText|overall|class|length|\n+--------------------+-------+-----+------+\n|Not much to write...|    5.0| like|   268|\n|The product does ...|    5.0| like|   544|\n|The primary job o...|    5.0| like|   436|\n|Nice windscreen p...|    5.0| like|   206|\n|This pop filter i...|    5.0| like|   159|\n+--------------------+-------+-----+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+------------------+-----------------+\n|   class|      avg(overall)|      avg(length)|\n+--------+------------------+-----------------+\n|not_like|1.5353319057815846|579.2055674518201|\n| neutral|               3.0|579.2111398963731|\n|    like|4.7690090888938155|473.1188206606074|\n+--------+------------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "data.groupby('class').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------+-----+\n|   class|count|\n+--------+-----+\n|not_like|  467|\n| neutral|  772|\n|    like| 9022|\n+--------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "data.groupBy('class').count().show()"
   ]
  },
  {
   "source": [
    "# 3. Feature transformations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer,VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='reviewText', outputCol='token_text')\n",
    "stopremove = StopWordsRemover(inputCol='token_text', outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens', outputCol='c_vec')\n",
    "idf = IDF(inputCol='c_vec', outputCol='tf_idf')\n",
    "class_to_num = StringIndexer(inputCol='class', outputCol='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols=['tf_idf', 'length'], outputCol='features')"
   ]
  },
  {
   "source": [
    "# 4. Pipeline "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipe = Pipeline(stages=[class_to_num, tokenizer, stopremove, count_vec, idf, clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipe.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(data)"
   ]
  },
  {
   "source": [
    "# 5. Tách dữ liệu train và test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select('label', 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(51949,[3,12,14,3...|\n|  0.0|(51949,[2,3,12,16...|\n|  0.0|(51949,[11,19,44,...|\n|  0.0|(51949,[18,37,57,...|\n|  0.0|(51949,[2,122,132...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "clean_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing = clean_data.randomSplit((.7, .3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0| 6373|\n|  1.0|  560|\n|  2.0|  323|\n+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "training.groupBy('label').count().show()"
   ]
  },
  {
   "source": [
    "# 6. Build model\n",
    "## 6.1. Bằng Naive Bayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = NaiveBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = nb.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = predictor.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n|label|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n|  0.0|(51949,[0],[1.025...|[-6.4303442138508...|[0.88433370870768...|       0.0|\n|  0.0|(51949,[0,1,2,3,4...|[-8039.6692015177...|[1.20288693328170...|       2.0|\n|  0.0|(51949,[0,1,2,3,4...|[-9444.5825286226...|[3.92316017105901...|       1.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "test_result.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------+-----+\n|label|prediction|count|\n+-----+----------+-----+\n|  2.0|       0.0|   63|\n|  1.0|       1.0|   75|\n|  0.0|       1.0|  532|\n|  1.0|       0.0|  123|\n|  2.0|       2.0|   33|\n|  2.0|       1.0|   48|\n|  1.0|       2.0|   14|\n|  0.0|       0.0| 1910|\n|  0.0|       2.0|  207|\n+-----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_result.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_eval = MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = acc_eval.evaluate(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7298356480665139"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "source": [
    "> **Nhận xét**\n",
    "> * Độ chính xác thấp"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6.2. Build bằng Logistic regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_1 = lg.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_1 = predictor_1.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------+-----+\n|label|prediction|count|\n+-----+----------+-----+\n|  2.0|       0.0|  139|\n|  1.0|       1.0|    2|\n|  0.0|       1.0|    3|\n|  1.0|       0.0|  209|\n|  2.0|       2.0|    3|\n|  2.0|       1.0|    2|\n|  1.0|       2.0|    1|\n|  0.0|       0.0| 2644|\n|  0.0|       2.0|    2|\n+-----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_result_1.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_1 = acc_eval.evaluate(test_result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8295721122041596"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "acc_1"
   ]
  },
  {
   "source": [
    "> **Nhận xét**\n",
    "> * Độ chính xác có cải thiện"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 6.3. Áp dụng random forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(labelCol='label', featuresCol='features', numTrees=500, maxDepth=5, maxBins=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_2 = rf.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_2 = rf.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_2 = predictor_2.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------+-----+\n|label|prediction|count|\n+-----+----------+-----+\n|  2.0|       0.0|  144|\n|  1.0|       0.0|  212|\n|  0.0|       0.0| 2649|\n+-----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_result_2.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_2 = acc_eval.evaluate(test_result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8260258371409047"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "acc_2"
   ]
  },
  {
   "source": [
    "> **Nhận xét**\n",
    "> * Độ chính xác cao nhưng kết quả cho ra ko tốt"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 8. Resampling data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "like_df = training.filter(col('label') == 0)\n",
    "neutral_df = training.filter(col('label') == 1)\n",
    "not_like_df = training.filter(col('label') == 2)\n",
    "ratio_1 = int(like_df.count()/neutral_df.count())\n",
    "ratio_2 = int(like_df.count()/not_like_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(11, 19)"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "ratio_1, ratio_2"
   ]
  },
  {
   "source": [
    "* Resample neutral"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = range(ratio_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_neutral_df = neutral_df.withColumn('dummy', explode(array([lit(x) for x in a1]))).drop('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = like_df.unionAll(oversampled_neutral_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(51949,[0],[1.025...|\n|  0.0|(51949,[0,1,2,3,4...|\n|  0.0|(51949,[0,1,2,3,4...|\n|  0.0|(51949,[0,1,2,3,4...|\n|  0.0|(51949,[0,1,2,3,4...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "combined_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0| 6373|\n|  1.0| 6160|\n+-----+-----+\n\n"
     ]
    }
   ],
   "source": [
    "combined_df.groupBy('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = range(ratio_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversampled_notlike_df = not_like_df.withColumn('dummy', explode(array([lit(x) for x in a2]))).drop('dummy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.unionAll(oversampled_notlike_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(51949,[0],[1.025...|\n|  0.0|(51949,[0,1,2,3,4...|\n|  0.0|(51949,[0,1,2,3,4...|\n|  0.0|(51949,[0,1,2,3,4...|\n|  0.0|(51949,[0,1,2,3,4...|\n+-----+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "combined_df.show(5)"
   ]
  },
  {
   "source": [
    "combined_df.groupBy('label').count().show()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+-----+\n|label|count|\n+-----+-----+\n|  0.0| 6373|\n|  1.0| 6160|\n|  2.0| 6137|\n+-----+-----+\n\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_4 = nb.fit(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_4 = predictor_4.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n|label|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n|  0.0|(51949,[0],[1.025...|[-7.3751807657850...|[0.32985809918260...|       1.0|\n|  0.0|(51949,[0,1,2,3,4...|[-8040.6140380697...|[1.0,5.6113723706...|       0.0|\n|  0.0|(51949,[0,1,2,3,4...|[-9445.5273651746...|[1.0,1.0949387349...|       0.0|\n|  0.0|(51949,[0,1,2,3,4...|[-19080.435082691...|       [1.0,0.0,0.0]|       0.0|\n|  0.0|(51949,[0,1,2,3,4...|[-3373.9498746200...|[1.0,1.7067128318...|       0.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "test_result_4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------+-----+\n|label|prediction|count|\n+-----+----------+-----+\n|  2.0|       0.0|  117|\n|  1.0|       1.0|   28|\n|  0.0|       1.0|  144|\n|  1.0|       0.0|  179|\n|  2.0|       2.0|   17|\n|  2.0|       1.0|   10|\n|  1.0|       2.0|    5|\n|  0.0|       0.0| 2449|\n|  0.0|       2.0|   56|\n+-----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_result_4.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.817836880816284"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "acc_eval.evaluate(test_result_4)"
   ]
  },
  {
   "source": [
    "<hr>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_5 = lg.fit(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_5 = predictor_5.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------+-----+\n|label|prediction|count|\n+-----+----------+-----+\n|  2.0|       0.0|  112|\n|  1.0|       1.0|   21|\n|  0.0|       1.0|   82|\n|  1.0|       0.0|  187|\n|  2.0|       2.0|   21|\n|  2.0|       1.0|   11|\n|  1.0|       2.0|    4|\n|  0.0|       0.0| 2554|\n|  0.0|       2.0|   13|\n+-----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_result_5.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8385517156955946"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "acc_eval.evaluate(test_result_5)"
   ]
  },
  {
   "source": [
    "<hr>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_6 = rf.fit(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result_6 = predictor_6.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-----+----------+-----+\n|label|prediction|count|\n+-----+----------+-----+\n|  2.0|       0.0|   98|\n|  1.0|       1.0|   23|\n|  0.0|       1.0|   39|\n|  1.0|       0.0|  178|\n|  2.0|       2.0|   39|\n|  2.0|       1.0|    7|\n|  1.0|       2.0|   11|\n|  0.0|       0.0| 2559|\n|  0.0|       2.0|   51|\n+-----+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "test_result_6.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8495029310028307"
      ]
     },
     "metadata": {},
     "execution_count": 72
    }
   ],
   "source": [
    "acc_eval.evaluate(test_result_6)"
   ]
  }
 ]
}