{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bit207240a302f84cf383d7b6dbf8fca3f2",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "![](../images/FE_00.png)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. Đọc dữ liệu đã làm sạch từ file parquet đã làm từ **part_1**"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Womens_Clothing_E_Commerce_Reviews').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(\"../data/womens-ecommerce-clothing-reviews/womens-ecommerce-clothing-reviews_clean_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---+------+--------------------+--------------+---------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+\n|Age|Rating|          ReviewText|RecommendedIND|PositiveFeedbackCount|ClassName|ClassName_idx|      ReviewText_tok|      ReviewText_stp|      ReviewText_cvt|      ReviewText_idf|\n+---+------+--------------------+--------------+---------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+\n| 46|     5|I tried these on ...|             1|                    8|    Pants|          4.0|[i, tried, these,...|[tried, whim, lik...|(14158,[3,8,14,19...|(14158,[3,8,14,19...|\n| 65|     4|Great feature...p...|             1|                    0|    Knits|          1.0|[great, feature, ...|[great, feature, ...|(14158,[3,5,8,16,...|(14158,[3,5,8,16,...|\n| 32|     3|I'm usually an xs...|             1|                    0|  Dresses|          0.0|[i, m, usually, a...|[m, usually, xs, ...|(14158,[0,4,6,10,...|(14158,[0,4,6,10,...|\n| 69|     4|Ordered this in w...|             1|                    1|Intimates|         15.0|[ordered, this, i...|[ordered, white, ...|(14158,[14,15,26,...|(14158,[14,15,26,...|\n| 39|     5|I was lucky enoug...|             1|                    0|  Dresses|          0.0|[i, was, lucky, e...|[lucky, enough, g...|(14158,[0,2,4,9,1...|(14158,[0,2,4,9,1...|\n+---+------+--------------------+--------------+---------------------+---------+-------------+--------------------+--------------------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "data.show(5)"
   ]
  },
  {
   "source": [
    "# 2. Chuyển dữ liệu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Age', 'RecommendedIND', 'PositiveFeedbackCount', 'ClassName_idx', 'ReviewText_idf']\n",
    "target = 'Rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=features, outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = assembler.transform(data).select('features', target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|            features|Rating|\n+--------------------+------+\n|(14162,[0,1,2,3,7...|     5|\n|(14162,[0,1,3,7,9...|     4|\n|(14162,[0,1,4,8,1...|     3|\n|(14162,[0,1,2,3,1...|     4|\n|(14162,[0,1,4,6,8...|     5|\n+--------------------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "final_data.show(5)"
   ]
  },
  {
   "source": [
    "# 3. Xem các group của `Rating` đã cân bằng chưa"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = final_data.groupBy(target).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+\n|Rating|count|\n+------+-----+\n|     1|  820|\n|     3| 2822|\n|     5|12523|\n|     4| 4907|\n|     2| 1548|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "tmp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "22620"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "tmp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = tmp.select('Rating', col('count')/tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+--------------------+\n|Rating|     (count / 22620)|\n+------+--------------------+\n|     1|0.036251105216622455|\n|     3| 0.12475685234305924|\n|     5|  0.5536251105216623|\n|     4|  0.2169319186560566|\n|     2| 0.06843501326259947|\n+------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "tmp2.show()"
   ]
  },
  {
   "source": [
    "> **Nhận xét**:\n",
    "> * Các group 1, 2, 3 chiếm số lượng quá nhỏ trong tập dữ liệu, cần oversampling chúng"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 4. Áp dụng Oversampling cho các group 1, 2, 3"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils import oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling(pDf: pyspark.sql.DataFrame, pColumn: str, pMajorValue, pMinorValue):\n",
    "data_sempling = oversampling(final_data, target, 4, 1)\n",
    "data_sempling = data_sempling.unionAll(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+\n|Rating|count|\n+------+-----+\n|     1| 4920|\n|     3| 2822|\n|     5|12523|\n|     4| 9814|\n|     2| 1548|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "data_sempling.groupBy(target).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sempling = oversampling(data_sempling, target, 3, 2).unionAll(data_sempling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+-----+\n|Rating|count|\n+------+-----+\n|     1| 4920|\n|     3| 5644|\n|     5|12523|\n|     4| 9814|\n|     2| 3096|\n+------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "data_sempling.groupBy(target).count().show()\n"
   ]
  },
  {
   "source": [
    "# 5. Tách dữ liệu train test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+\n|            features|Rating|\n+--------------------+------+\n|(14162,[0,1,4,8,1...|     3|\n|(14162,[0,1,2,3,8...|     3|\n|(14162,[0,3,5,12,...|     3|\n|(14162,[0,2,3,5,1...|     3|\n|(14162,[0,1,2,3,1...|     3|\n+--------------------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "data_sempling.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data_sempling.randomSplit((0.8, 0.2))"
   ]
  },
  {
   "source": [
    "# 6. Build model\n",
    "## 6.1. Logistic Regression\n",
    "### 6.1.1. Build model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(labelCol=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model_0 = logistic.fit(train)"
   ]
  },
  {
   "source": [
    "### 6.1.2. Đánh giá model\n",
    "#### 6.1.2.1. Trên train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "logistic_train_res_0 = logistic_model_0.evaluate(train).predictions"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+------+--------------------+--------------------+----------+\n|            features|Rating|       rawPrediction|         probability|prediction|\n+--------------------+------+--------------------+--------------------+----------+\n|(14162,[0,1,2,3,5...|     3|[-7.3181929902304...|[2.34541327520655...|       3.0|\n|(14162,[0,1,2,3,5...|     3|[-7.3149864739762...|[4.30765709377436...|       3.0|\n|(14162,[0,1,2,3,5...|     3|[-7.3557883676591...|[2.89017751363039...|       3.0|\n|(14162,[0,1,2,3,5...|     3|[-7.2561252794319...|[4.93238017023871...|       3.0|\n|(14162,[0,1,2,3,5...|     3|[-7.3643769181560...|[5.40030642297963...|       3.0|\n+--------------------+------+--------------------+--------------------+----------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "logistic_train_res_0.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+----------+-----+\n|Rating|prediction|count|\n+------+----------+-----+\n|     5|       4.0|  131|\n|     4|       4.0| 7724|\n|     5|       5.0| 9909|\n|     4|       5.0|  120|\n|     3|       3.0| 4513|\n|     3|       5.0|    1|\n|     2|       2.0| 2498|\n|     1|       1.0| 3887|\n+------+----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "logistic_train_res_0.groupBy(target, 'prediction').count().show()"
   ]
  },
  {
   "source": [
    "#### 6.1.2.2. Trên test data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_test_res_0 = logistic_model_0.evaluate(test).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------+----------+-----+\n|Rating|prediction|count|\n+------+----------+-----+\n|     2|       1.0|   12|\n|     4|       3.0|   34|\n|     2|       4.0|   24|\n|     4|       1.0|    6|\n|     3|       4.0|   52|\n|     5|       4.0|  647|\n|     3|       1.0|   12|\n|     4|       4.0| 1670|\n|     5|       5.0| 1669|\n|     5|       2.0|   31|\n|     5|       1.0|    5|\n|     2|       3.0|   30|\n|     3|       2.0|   48|\n|     4|       5.0|  254|\n|     3|       3.0|  971|\n|     3|       5.0|   47|\n|     2|       2.0|  524|\n|     1|       1.0| 1033|\n|     5|       3.0|  131|\n|     2|       5.0|    8|\n+------+----------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "logistic_test_res_0.groupBy(target, 'prediction').count().show()"
   ]
  },
  {
   "source": [
    "#### 6.1.2.3. Confusion matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_labels = logistic_test_res_0.withColumnRenamed('Rating', 'label').select('prediction', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    label  prediction  count\n",
       "0       2         1.0     12\n",
       "1       4         3.0     34\n",
       "2       2         4.0     24\n",
       "3       4         1.0      6\n",
       "4       3         4.0     52\n",
       "5       5         4.0    647\n",
       "6       3         1.0     12\n",
       "7       4         4.0   1670\n",
       "8       5         5.0   1669\n",
       "9       5         2.0     31\n",
       "10      5         1.0      5\n",
       "11      2         3.0     30\n",
       "12      3         2.0     48\n",
       "13      4         5.0    254\n",
       "14      3         3.0    971\n",
       "15      3         5.0     47\n",
       "16      2         2.0    524\n",
       "17      1         1.0   1033\n",
       "18      5         3.0    131\n",
       "19      2         5.0      8\n",
       "20      4         2.0      6"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>prediction</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>3.0</td>\n      <td>34</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4.0</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1.0</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>4.0</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>4.0</td>\n      <td>647</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3</td>\n      <td>1.0</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>4</td>\n      <td>4.0</td>\n      <td>1670</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>5</td>\n      <td>5.0</td>\n      <td>1669</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>5</td>\n      <td>2.0</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>5</td>\n      <td>1.0</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2</td>\n      <td>3.0</td>\n      <td>30</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>3</td>\n      <td>2.0</td>\n      <td>48</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>4</td>\n      <td>5.0</td>\n      <td>254</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>3</td>\n      <td>3.0</td>\n      <td>971</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>3</td>\n      <td>5.0</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>2</td>\n      <td>2.0</td>\n      <td>524</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1033</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>5</td>\n      <td>3.0</td>\n      <td>131</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2</td>\n      <td>5.0</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>4</td>\n      <td>2.0</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "predictions_labels.groupBy('label', 'prediction').count().toPandas()"
   ]
  },
  {
   "source": [
    "#### 6.1.2.4. Dựa theo **Accuracy**, **F1-Score**, **Precision**, **Recall** "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8132797338508456"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "evaluator.evaluate(predictions_labels, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8118683688883603"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "evaluator.evaluate(predictions_labels, {evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8212661632762287"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "evaluator.evaluate(predictions_labels, {evaluator.metricName: \"weightedPrecision\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8132797338508455"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "evaluator.evaluate(predictions_labels, {evaluator.metricName: \"weightedRecall\"})"
   ]
  },
  {
   "source": [
    "> **Nhận xét:**\n",
    "> * Các chỉ số đánh giá sức mạnh của model nhìn chung rất tốt, đều trên 80%."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}